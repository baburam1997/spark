{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b051b08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/06/08 09:21:03 WARN Utils: Your hostname, FM-PC-LT-323 resolves to a loopback address: 127.0.1.1; using 172.16.5.219 instead (on interface wlp0s20f3)\n",
      "23/06/08 09:21:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/06/08 09:21:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/06/08 09:21:05 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/06/08 09:21:05 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "23/06/08 09:21:05 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Aggregations\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ede9d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   537226|    22811|SET OF 6 T-LIGHTS...|       6|2010-12-06 08:34:00|     2.95|   15987.0|United Kingdom|\n",
      "|   537226|    21713|CITRONELLA CANDLE...|       8|2010-12-06 08:34:00|      2.1|   15987.0|United Kingdom|\n",
      "|   537226|    22927|GREEN GIANT GARDE...|       2|2010-12-06 08:34:00|     5.95|   15987.0|United Kingdom|\n",
      "|   537226|    20802|SMALL GLASS SUNDA...|       6|2010-12-06 08:34:00|     1.65|   15987.0|United Kingdom|\n",
      "|   537226|    22052|VINTAGE CARAVAN G...|      25|2010-12-06 08:34:00|     0.42|   15987.0|United Kingdom|\n",
      "|   537226|    22705|   WRAP GREEN PEARS |      25|2010-12-06 08:34:00|     0.42|   15987.0|United Kingdom|\n",
      "|   537226|    20781|GOLD EAR MUFF HEA...|       2|2010-12-06 08:34:00|     5.49|   15987.0|United Kingdom|\n",
      "|   537226|    22310|IVORY KNITTED MUG...|       6|2010-12-06 08:34:00|     1.65|   15987.0|United Kingdom|\n",
      "|   537226|    22389|PAPERWEIGHT SAVE ...|       6|2010-12-06 08:34:00|     2.55|   15987.0|United Kingdom|\n",
      "|   537227|    22941|CHRISTMAS LIGHTS ...|       2|2010-12-06 08:42:00|      8.5|   17677.0|United Kingdom|\n",
      "|   537227|    22696| WICKER WREATH LARGE|       6|2010-12-06 08:42:00|     1.95|   17677.0|United Kingdom|\n",
      "|   537227|    22193|RED DINER WALL CLOCK|       2|2010-12-06 08:42:00|      8.5|   17677.0|United Kingdom|\n",
      "|   537227|    21212|PACK OF 72 RETROS...|     120|2010-12-06 08:42:00|     0.42|   17677.0|United Kingdom|\n",
      "|   537227|    21977|PACK OF 60 PINK P...|      48|2010-12-06 08:42:00|     0.55|   17677.0|United Kingdom|\n",
      "|   537227|    84991|60 TEATIME FAIRY ...|      48|2010-12-06 08:42:00|     0.55|   17677.0|United Kingdom|\n",
      "|   537227|    21213|PACK OF 72 SKULL ...|      48|2010-12-06 08:42:00|     0.55|   17677.0|United Kingdom|\n",
      "|   537227|    21080|SET/20 RED RETROS...|      12|2010-12-06 08:42:00|     0.85|   17677.0|United Kingdom|\n",
      "|   537227|    22632|HAND WARMER RED R...|      48|2010-12-06 08:42:00|      2.1|   17677.0|United Kingdom|\n",
      "|   537227|    22315|200 RED + WHITE B...|      12|2010-12-06 08:42:00|     1.25|   17677.0|United Kingdom|\n",
      "|   537227|    21232|STRAWBERRY CERAMI...|      12|2010-12-06 08:42:00|     1.25|   17677.0|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retail_data_df = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .load(\"data/csv/retail_data/*.csv\")\\\n",
    "    .coalesce(5)\n",
    "\n",
    "retail_data_df.cache()\n",
    "retail_data_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2984f327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14022"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retail_data_df.count()\n",
    "# 14022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "670fd2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: timestamp (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: double (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retail_data_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62f7486",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3101252a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|count(StockCode)|\n",
      "+----------------+\n",
      "|           14022|\n",
      "+----------------+\n",
      "\n",
      "+-------------------------+\n",
      "|count(DISTINCT StockCode)|\n",
      "+-------------------------+\n",
      "|                     2230|\n",
      "+-------------------------+\n",
      "\n",
      "+--------------------------------+\n",
      "|approx_count_distinct(StockCode)|\n",
      "+--------------------------------+\n",
      "|                            2155|\n",
      "+--------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count,countDistinct,approx_count_distinct\n",
    "retail_data_df.select(count(\"StockCode\")).show() # 14022\n",
    "\n",
    "retail_data_df.select(countDistinct(\"StockCode\")).show() # 2230\n",
    "\n",
    "retail_data_df.select(approx_count_distinct(\"StockCode\",0.2)).show() # 2155 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8b5b282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "| first(InvoiceDate)|  last(InvoiceDate)|\n",
      "+-------------------+-------------------+\n",
      "|2010-12-06 08:34:00|2010-12-03 17:28:00|\n",
      "+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import first, last\n",
    "\n",
    "retail_data_df.select(first(\"InvoiceDate\"), last(\"InvoiceDate\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a61f1fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+------------------+------------------+\n",
      "|(total_purchases / total_transactions)|     avg_purchases|    mean_purchases|\n",
      "+--------------------------------------+------------------+------------------+\n",
      "|                    7.1659535016402796|7.1659535016402796|7.1659535016402796|\n",
      "+--------------------------------------+------------------+------------------+\n",
      "\n",
      "+-------------+-------------+\n",
      "|min(Quantity)|max(Quantity)|\n",
      "+-------------+-------------+\n",
      "|        -9360|         2880|\n",
      "+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum, count, avg, expr, min, max\n",
    "retail_data_df\\\n",
    "    .select(count(\"Quantity\").alias(\"total_transactions\"),\n",
    "            sum(\"Quantity\").alias(\"total_purchases\"),\n",
    "            avg(\"Quantity\").alias(\"avg_purchases\"),\n",
    "            expr(\"mean(Quantity)\").alias(\"mean_purchases\"))\\\n",
    "    .selectExpr(\"total_purchases/total_transactions\",\"avg_purchases\",\"mean_purchases\")\\\n",
    "    .show()\n",
    "\n",
    "retail_data_df\\\n",
    "    .select(min(\"Quantity\"),max(\"Quantity\"))\\\n",
    "    .show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf729f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------------+----------------------+\n",
      "|sum(Quantity)|sum(DISTINCT Quantity)|sum(DISTINCT Quantity)|\n",
      "+-------------+----------------------+----------------------+\n",
      "|       100481|                  4844|                  4844|\n",
      "+-------------+----------------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum, sumDistinct, sum_distinct\n",
    "\n",
    "retail_data_df.select(sum(\"Quantity\"),sumDistinct(\"Quantity\"),sum_distinct(\"Quantity\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1cafe8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+-----------------------------+-----------------+------------------+--------------------+---------------------+\n",
      "|Default_var_samp(Quantity)|Default_stddev_samp(Quantity)|var_pop(Quantity)|var_samp(Quantity)|stddev_pop(Quantity)|stddev_samp(Quantity)|\n",
      "+--------------------------+-----------------------------+-----------------+------------------+--------------------+---------------------+\n",
      "|          7843.58539520731|            88.56401862611763|7843.026018128776|  7843.58539520731|   88.56086053177654|    88.56401862611763|\n",
      "+--------------------------+-----------------------------+-----------------+------------------+--------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import variance, stddev\n",
    "from pyspark.sql.functions import var_pop, stddev_pop\n",
    "from pyspark.sql.functions import var_samp, stddev_samp\n",
    "\n",
    "retail_data_df\\\n",
    "    .select(variance(\"Quantity\").alias(\"Default_var_samp(Quantity)\"),\n",
    "            stddev(\"Quantity\").alias(\"Default_stddev_samp(Quantity)\"),\n",
    "            var_pop(\"Quantity\"), \n",
    "            var_samp(\"Quantity\"),\n",
    "            stddev_pop(\"Quantity\"), \n",
    "            stddev_samp(\"Quantity\"))\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aab891cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|skewness(Quantity)|kurtosis(Quantity)|\n",
      "+------------------+------------------+\n",
      "|-80.58047369410305| 9024.825827028237|\n",
      "+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import skewness, kurtosis\n",
    "\n",
    "retail_data_df.select(skewness(\"Quantity\"), kurtosis(\"Quantity\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d7d20bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-------------------------------+------------------------------+\n",
      "|corr(InvoiceNo, Quantity)|covar_samp(InvoiceNo, Quantity)|covar_pop(InvoiceNo, Quantity)|\n",
      "+-------------------------+-------------------------------+------------------------------+\n",
      "|      -0.0488744918095809|             -623.2038275092896|            -623.1589054428649|\n",
      "+-------------------------+-------------------------------+------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import corr, covar_pop, covar_samp\n",
    "\n",
    "retail_data_df\\\n",
    "    .select(corr(\"InvoiceNo\", \"Quantity\"), \n",
    "            covar_samp(\"InvoiceNo\", \"Quantity\"),\n",
    "            covar_pop(\"InvoiceNo\", \"Quantity\"))\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "20a61cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+\n",
      "|collect_set(Country)|collect_list(Country)|\n",
      "+--------------------+---------------------+\n",
      "|[Portugal, Italy,...| [United Kingdom, ...|\n",
      "+--------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import collect_set, collect_list\n",
    "\n",
    "retail_data_df.agg(collect_set(\"Country\"), collect_list(\"Country\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "00a20533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|InvoiceNo|count|\n",
      "+---------+-----+\n",
      "|   537252|    1|\n",
      "|   537439|    1|\n",
      "|   537246|    7|\n",
      "|   537256|   11|\n",
      "|   537350|   12|\n",
      "|   537228|    1|\n",
      "|   537298|    9|\n",
      "|   537436|    1|\n",
      "|   537368|   15|\n",
      "|   537245|    3|\n",
      "|   537412|    1|\n",
      "|   537243|    2|\n",
      "|   537351|   32|\n",
      "|   537354|   38|\n",
      "|  C537373|    1|\n",
      "|   537435|   14|\n",
      "|  C537408|    2|\n",
      "|   537378|   20|\n",
      "|   537231|   18|\n",
      "|   537312|    9|\n",
      "+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------+-----+\n",
      "|CustomerId|count|\n",
      "+----------+-----+\n",
      "|   13094.0|    3|\n",
      "|   17884.0|   64|\n",
      "|   16858.0|   10|\n",
      "|   15898.0|   59|\n",
      "|   16550.0|   51|\n",
      "|   17320.0|   22|\n",
      "|   18219.0|   13|\n",
      "|   13089.0|   41|\n",
      "|   17218.0|   51|\n",
      "|   16654.0|    9|\n",
      "|   14409.0|    3|\n",
      "|   15899.0|    4|\n",
      "|   15987.0|    9|\n",
      "|      null| 4195|\n",
      "|   15882.0|   17|\n",
      "|   13030.0|   60|\n",
      "|   17920.0|   95|\n",
      "|   17682.0|   18|\n",
      "|   18113.0|    1|\n",
      "|   14867.0|    1|\n",
      "+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+---------+----------+-----+\n",
      "|InvoiceNo|CustomerId|count|\n",
      "+---------+----------+-----+\n",
      "|   537252|      null|    1|\n",
      "|   537439|      null|    1|\n",
      "|   537423|   14215.0|    6|\n",
      "|   537395|   15356.0|   53|\n",
      "|   537424|   15602.0|    3|\n",
      "|   537388|   17682.0|   18|\n",
      "|   537436|      null|    1|\n",
      "|   537242|   14748.0|   29|\n",
      "|   537374|   17259.0|   87|\n",
      "|   537265|   15919.0|   49|\n",
      "|   537403|   17191.0|   11|\n",
      "|  C537417|   13481.0|    1|\n",
      "|   537418|   17884.0|   36|\n",
      "|   537375|   17019.0|   49|\n",
      "|   537381|   14667.0|   24|\n",
      "|   537257|   17691.0|    9|\n",
      "|  C537234|   16161.0|    1|\n",
      "|   537377|   15882.0|   14|\n",
      "|   537396|   17223.0|   30|\n",
      "|   537387|   13468.0|   14|\n",
      "+---------+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retail_data_df.groupBy(\"InvoiceNo\").count().show()\n",
    "retail_data_df.groupBy(\"CustomerId\").count().show()\n",
    "retail_data_df.groupBy(\"InvoiceNo\", \"CustomerId\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "388372d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+---------------+\n",
      "|InvoiceNo|quantity|count(Quantity)|\n",
      "+---------+--------+---------------+\n",
      "|   537252|       1|              1|\n",
      "|   537439|       1|              1|\n",
      "|   537246|       7|              7|\n",
      "|   537256|      11|             11|\n",
      "|   537350|      12|             12|\n",
      "|   537228|       1|              1|\n",
      "|   537298|       9|              9|\n",
      "|   537436|       1|              1|\n",
      "|   537368|      15|             15|\n",
      "|   537245|       3|              3|\n",
      "|   537412|       1|              1|\n",
      "|   537243|       2|              2|\n",
      "|   537351|      32|             32|\n",
      "|   537354|      38|             38|\n",
      "|  C537373|       1|              1|\n",
      "|   537435|      14|             14|\n",
      "|  C537408|       2|              2|\n",
      "|   537378|      20|             20|\n",
      "|   537231|      18|             18|\n",
      "|   537312|       9|              9|\n",
      "+---------+--------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count\n",
    "\n",
    "retail_data_df\\\n",
    "    .groupBy(\"InvoiceNo\")\\\n",
    "    .agg(count(\"Quantity\").alias(\"quantity\"),\n",
    "         expr(\"count(Quantity)\")\n",
    "        )\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f4e37e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+------------------+----------------+--------------+------------------+\n",
      "|InvoiceNo|     avg(Quantity)|    mean(Quantity)|median(Quantity)|mode(Quantity)|  stddev(Quantity)|\n",
      "+---------+------------------+------------------+----------------+--------------+------------------+\n",
      "|   536365| 5.714285714285714| 5.714285714285714|             6.0|             6| 1.799470821684875|\n",
      "|   536366|               6.0|               6.0|             6.0|             6|               0.0|\n",
      "|   536367| 6.916666666666667| 6.916666666666667|             5.0|             6|  8.09554684921771|\n",
      "|   536368|              3.75|              3.75|             3.0|             3|               1.5|\n",
      "|   536369|               3.0|               3.0|             3.0|             3|              null|\n",
      "|   536370|             22.45|             22.45|            24.0|            24| 9.167878707749137|\n",
      "|   536371|              80.0|              80.0|            80.0|            80|              null|\n",
      "|   536372|               6.0|               6.0|             6.0|             6|               0.0|\n",
      "|   536373|               5.5|               5.5|             6.0|             6|1.5491933384829668|\n",
      "|   536374|              32.0|              32.0|            32.0|            32|              null|\n",
      "|   536375|               5.5|               5.5|             6.0|             6|1.5491933384829668|\n",
      "|   536376|              56.0|              56.0|            56.0|            48|11.313708498984761|\n",
      "|   536377|               6.0|               6.0|             6.0|             6|               0.0|\n",
      "|   536378|23.894736842105264|23.894736842105264|            10.0|            10| 31.56280289067797|\n",
      "|   536380|              24.0|              24.0|            24.0|            24|              null|\n",
      "|   536381|5.6571428571428575|5.6571428571428575|             2.0|             1| 8.320572863277459|\n",
      "|   536382|11.166666666666666|11.166666666666666|             9.0|            12|12.805065285647588|\n",
      "|   536384|14.615384615384615|14.615384615384615|             6.0|             6|16.393791820576784|\n",
      "|   536385| 7.571428571428571| 7.571428571428571|            10.0|            12| 4.613644360558611|\n",
      "|   536386| 78.66666666666667| 78.66666666666667|           100.0|           100|36.950417228136054|\n",
      "+---------+------------------+------------------+----------------+--------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retail_data_df\\\n",
    "    .groupBy(\"InvoiceNo\")\\\n",
    "    .agg(expr(\"avg(Quantity)\"),\n",
    "         expr(\"mean(Quantity)\"),\n",
    "         expr(\"median(Quantity)\"),\n",
    "         expr(\"mode(Quantity)\"),\n",
    "         expr(\"stddev(Quantity)\")\n",
    "        )\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "21bedcfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|      date|\n",
      "+----------+\n",
      "|2010-12-06|\n",
      "|2010-12-06|\n",
      "|2010-12-06|\n",
      "|2010-12-06|\n",
      "|2010-12-06|\n",
      "|2010-12-06|\n",
      "|2010-12-06|\n",
      "|2010-12-06|\n",
      "|2010-12-06|\n",
      "|2010-12-06|\n",
      "|2010-12-06|\n",
      "|2010-12-06|\n",
      "|2010-12-06|\n",
      "|2010-12-06|\n",
      "|2010-12-06|\n",
      "|2010-12-06|\n",
      "|2010-12-06|\n",
      "|2010-12-06|\n",
      "|2010-12-06|\n",
      "|2010-12-06|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, to_date\n",
    "dfWithDate = retail_data_df.withColumn(\"date\", to_date(col(\"InvoiceDate\"), \"MM/d/yyyy H:mm:ss\"))\n",
    "dfWithDate.select(\"date\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e56482",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baf7401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba8f816",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
