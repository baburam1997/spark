{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24df141b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/06/08 09:01:26 WARN Utils: Your hostname, FM-PC-LT-323 resolves to a loopback address: 127.0.1.1; using 172.16.5.219 instead (on interface wlp0s20f3)\n",
      "23/06/08 09:01:26 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/06/08 09:01:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/06/08 09:01:28 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/06/08 09:01:28 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"Working with Different Types of Files\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e804dc",
   "metadata": {},
   "source": [
    "# CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5997fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|       United States|            Romania|   15|\n",
      "|       United States|            Croatia|    1|\n",
      "|       United States|            Ireland|  344|\n",
      "|               Egypt|      United States|   15|\n",
      "|       United States|              India|   62|\n",
      "|       United States|          Singapore|    1|\n",
      "|       United States|            Grenada|   62|\n",
      "|          Costa Rica|      United States|  588|\n",
      "|             Senegal|      United States|   40|\n",
      "|             Moldova|      United States|    1|\n",
      "|       United States|       Sint Maarten|  325|\n",
      "|       United States|   Marshall Islands|   39|\n",
      "|              Guyana|      United States|   64|\n",
      "|               Malta|      United States|    1|\n",
      "|            Anguilla|      United States|   41|\n",
      "|             Bolivia|      United States|   30|\n",
      "|       United States|           Paraguay|    6|\n",
      "|             Algeria|      United States|    4|\n",
      "|Turks and Caicos ...|      United States|  230|\n",
      "|       United States|          Gibraltar|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summery_csv = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"mode\", \"FAILFAST\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .load(\"data/csv/2015-summary.csv\")\n",
    "summery_csv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4c1b18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|            Ireland|  344|\n",
      "|            Egypt|      United States|   15|\n",
      "|    United States|              India|   62|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructField, StructType, StringType, LongType\n",
    "myManualSchema = StructType([\n",
    "    StructField(\"DEST_COUNTRY_NAME\", StringType(), True),\n",
    "    StructField(\"ORIGIN_COUNTRY_NAME\", StringType(), True),\n",
    "    StructField(\"count\", LongType(), False)\n",
    "])\n",
    "summery_csv1 = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"mode\", \"FAILFAST\")\\\n",
    "    .schema(myManualSchema)\\\n",
    "    .load(\"data/csv/2015-summary.csv\")\\\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f79108f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "summery_csv.write.format(\"csv\").mode(\"overwrite\").option(\"sep\", \",\")\\\n",
    "    .save(\"data/csv/my-csv-file.csv\")\n",
    "summery_csv.write.format(\"csv\").mode(\"overwrite\").option(\"sep\", \"\\t\")\\\n",
    "    .save(\"data/csv/my-tsv-file.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76105864",
   "metadata": {},
   "source": [
    "# Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f59cce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|       United States|            Romania|   15|\n",
      "|       United States|            Croatia|    1|\n",
      "|       United States|            Ireland|  344|\n",
      "|               Egypt|      United States|   15|\n",
      "|       United States|              India|   62|\n",
      "|       United States|          Singapore|    1|\n",
      "|       United States|            Grenada|   62|\n",
      "|          Costa Rica|      United States|  588|\n",
      "|             Senegal|      United States|   40|\n",
      "|             Moldova|      United States|    1|\n",
      "|       United States|       Sint Maarten|  325|\n",
      "|       United States|   Marshall Islands|   39|\n",
      "|              Guyana|      United States|   64|\n",
      "|               Malta|      United States|    1|\n",
      "|            Anguilla|      United States|   41|\n",
      "|             Bolivia|      United States|   30|\n",
      "|       United States|           Paraguay|    6|\n",
      "|             Algeria|      United States|    4|\n",
      "|Turks and Caicos ...|      United States|  230|\n",
      "|       United States|          Gibraltar|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary_json = spark.read.format(\"json\").option(\"mode\", \"FAILFAST\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .load(\"data/json/2015-summary.json\")\n",
    "summary_json.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba917b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_json.write.format(\"json\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .save(\"data/json/my-json-file.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa42e0e",
   "metadata": {},
   "source": [
    "# parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e8a0421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|    1|\n",
      "|    United States|            Ireland|  264|\n",
      "|    United States|              India|   69|\n",
      "|            Egypt|      United States|   24|\n",
      "|Equatorial Guinea|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parquet_data = spark.read.format(\"parquet\")\\\n",
    "    .load(\"data/parquet/parquet_data.parquet\")\n",
    "\n",
    "parquet_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15662982",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_data.write.format(\"parquet\").mode(\"overwrite\")\\\n",
    "    .save(\"data/parquet/my-parquet-file.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3abf201",
   "metadata": {},
   "source": [
    "# Orc Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a03c3a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|    1|\n",
      "|    United States|            Ireland|  264|\n",
      "|    United States|              India|   69|\n",
      "|            Egypt|      United States|   24|\n",
      "|Equatorial Guinea|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orc_data = spark.read.format(\"orc\").load(\"data/orc/orc_data.orc\")\n",
    "\n",
    "orc_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d9d4d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "orc_data.write.format(\"orc\").mode(\"overwrite\").save(\"data/orc/my-orc-file.orc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c57c32",
   "metadata": {},
   "source": [
    "# text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "288d3914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                rows|\n",
      "+--------------------+\n",
      "|[appName,  Sets t...|\n",
      "|[Example,  .appNa...|\n",
      "|                  []|\n",
      "|[master,  Specifi...|\n",
      "|[Example,  .maste...|\n",
      "|                  []|\n",
      "|[config,  Allows ...|\n",
      "|[Example,  .confi...|\n",
      "|                  []|\n",
      "|[enableHiveSuppor...|\n",
      "|[Example,  .enabl...|\n",
      "|                  []|\n",
      "|[spark.executor.m...|\n",
      "|[Example,  .confi...|\n",
      "|                  []|\n",
      "|[spark.driver.mem...|\n",
      "|[Example,  .confi...|\n",
      "|                  []|\n",
      "|[spark.sql.shuffl...|\n",
      "|[Example,  .confi...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_data = spark.read.text(\"data/text/sample_text_data.txt\")\n",
    "text_data.selectExpr(\"split(value, ':') as rows\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05b5fda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data.write.text(\"data/text/my-simple-text-files.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9fd77f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "summery_csv.limit(10).select(\"DEST_COUNTRY_NAME\", \"count\")\\\n",
    "    .write.partitionBy(\"count\").text(\"data/text/five-csv-partition-filespy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdb4ddfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764b647d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47405a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
