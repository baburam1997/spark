{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/15 03:35:40 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder\\\n",
    "    .appName(\"DataFrame Heading Cleaning and Renaming\")\\\n",
    "        .master(\"local[2]\")\\\n",
    "            .config(\"spark.executor.memory\", \"2g\")\\\n",
    "                .config(\"spark.driver.memory\", \"1g\")\\\n",
    "                    .config(\"spark.sql.shuffle.partitions\", \"4\")\\\n",
    "                        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the options and configurations\n",
    "options = {\n",
    "    \"header\": \"true\",          # Use the first row as the header\n",
    "    \"inferSchema\": \"true\",     # Infer the schema of the CSV file\n",
    "    \"sep\": \",\",                # Specify the separator (default is ',')\n",
    "    \"encoding\": \"UTF-8\",       # Set the character encoding\n",
    "    \"mode\": \"DROPMALFORMED\"    # Handle malformed rows by dropping them\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'input-data/person_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Person@ ID: integer (nullable = true)\n",
      " |-- First, Name: string (nullable = true)\n",
      " |-- Last! Name: string (nullable = true)\n",
      " |-- Date* Of Birth: date (nullable = true)\n",
      " |-- Gender#: string (nullable = true)\n",
      " |-- Email$ Address: string (nullable = true)\n",
      " |-- Phone% Number: long (nullable = true)\n",
      " |-- Address^: string (nullable = true)\n",
      " |-- City (State): string (nullable = true)\n",
      " |-- Zip Code|: integer (nullable = true)\n",
      " |-- Country~: string (nullable = true)\n",
      " |-- Nationality`: string (nullable = true)\n",
      " |-- Occupation_: string (nullable = true)\n",
      " |-- Education+: string (nullable = true)\n",
      " |-- Marital-Status: string (nullable = true)\n",
      " |-- Registration. Date: date (nullable = true)\n",
      " |-- Registration TIme: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file with the specified options\n",
    "df = spark.read.csv(csv_file_path, **options)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- person_id: integer (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- date_of_birth: date (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- email_address: string (nullable = true)\n",
      " |-- phone_number: long (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- city_state: string (nullable = true)\n",
      " |-- zip_code: integer (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- nationality: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- marital_status: string (nullable = true)\n",
      " |-- registration_date: date (nullable = true)\n",
      " |-- registration_time: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# Define a custom function to clean column names\n",
    "def clean_column_name(name):\n",
    "    # Remove special characters, spaces, and convert to lowercase\n",
    "    cleaned_name = re.sub(r'[^a-zA-Z0-9]+', ' ', name).strip('_').lower()\n",
    "    return cleaned_name\n",
    "\n",
    "# Apply the custom function to rename columns\n",
    "for col in df.columns:\n",
    "    new_col_name = clean_column_name(col)\n",
    "    df = df.withColumnRenamed(col, new_col_name)\n",
    "\n",
    "# Remove leading and trailing underscores from column names\n",
    "def remove_leading_trailing_underscores_from_column_names(df, leading_trailing_underscores=True):\n",
    "    for col in df.columns:\n",
    "        if leading_trailing_underscores:\n",
    "            df = df.withColumnRenamed(col, col.strip('_'))\n",
    "    return df\n",
    "\n",
    "df = remove_leading_trailing_underscores_from_column_names(df)\n",
    "\n",
    "# Remove leading and trailing spaces from column names\n",
    "def remove_leading_trailing_spaces_from_column_names(df, leading_trailing_spaces=True):\n",
    "    for col in df.columns:\n",
    "        if leading_trailing_spaces:\n",
    "            df = df.withColumnRenamed(col, col.strip())\n",
    "    return df\n",
    "\n",
    "df = remove_leading_trailing_spaces_from_column_names(df)\n",
    "\n",
    "# Join words with underscores in column names\n",
    "def join_words_with_spaces_in_column_names(df, join_by_space=True):\n",
    "    for col in df.columns:\n",
    "        if join_by_space:\n",
    "            df = df.withColumnRenamed(col, \"_\".join(col.split()))\n",
    "    return df\n",
    "\n",
    "df = join_words_with_spaces_in_column_names(df)\n",
    "\n",
    "# Convert column names to lowercase\n",
    "def lowercase_dataframe_column_names(df, lower_case=True):\n",
    "    for col in df.columns:\n",
    "        if lower_case:\n",
    "            df = df.withColumnRenamed(col, col.lower())\n",
    "    return df\n",
    "\n",
    "df = lowercase_dataframe_column_names(df)\n",
    "\n",
    "# Show the DataFrame\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Person@ ID: integer (nullable = true)\n",
      " |-- First, Name: string (nullable = true)\n",
      " |-- Last! Name: string (nullable = true)\n",
      " |-- Date* Of Birth: date (nullable = true)\n",
      " |-- Gender#: string (nullable = true)\n",
      " |-- Email$ Address: string (nullable = true)\n",
      " |-- Phone% Number: long (nullable = true)\n",
      " |-- Address^: string (nullable = true)\n",
      " |-- City (State): string (nullable = true)\n",
      " |-- Zip Code|: integer (nullable = true)\n",
      " |-- Country~: string (nullable = true)\n",
      " |-- Nationality`: string (nullable = true)\n",
      " |-- Occupation_: string (nullable = true)\n",
      " |-- Education+: string (nullable = true)\n",
      " |-- Marital-Status: string (nullable = true)\n",
      " |-- Registration. Date: date (nullable = true)\n",
      " |-- Registration TIme: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file with the specified options\n",
    "df = spark.read.csv(csv_file_path, **options)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- person_id: integer (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- date_of_birth: date (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- email_address: string (nullable = true)\n",
      " |-- phone_number: long (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- city_state: string (nullable = true)\n",
      " |-- zip_code: integer (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- nationality: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- marital_status: string (nullable = true)\n",
      " |-- registration_date: date (nullable = true)\n",
      " |-- registration_time: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# Define a custom function to clean column names\n",
    "def clean_and_transform_column_names(\n",
    "        df,\n",
    "        remove_special_chars=True, \n",
    "        remove_underscores=True,\n",
    "        remove_spaces=True, \n",
    "        join_with_underscores=True, \n",
    "        lowercase=True\n",
    "        ):\n",
    "    for col in df.columns:\n",
    "        new_col_name = col\n",
    "        # Remove special characters and replace spaces with \"\"\n",
    "        if remove_special_chars:\n",
    "            new_col_name = re.sub(r'[^a-zA-Z0-9]+', ' ', new_col_name)\n",
    "        # Remove leading and trailing underscores\n",
    "        if remove_underscores:\n",
    "            new_col_name = new_col_name.strip('_')\n",
    "        # Remove leading and trailing spaces\n",
    "        if remove_spaces:\n",
    "            new_col_name = new_col_name.strip()\n",
    "        # Join words with underscores\n",
    "        if join_with_underscores:\n",
    "            new_col_name = \"_\".join(new_col_name.split())\n",
    "        # Convert to lowercase\n",
    "        if lowercase:\n",
    "            new_col_name = new_col_name.lower()\n",
    "        # Rename the column\n",
    "        df = df.withColumnRenamed(col, new_col_name)\n",
    "    return df\n",
    "\n",
    "# Clean and transform column names using a single function\n",
    "df = clean_and_transform_column_names(df)\n",
    "\n",
    "# Show the DataFrame Schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
